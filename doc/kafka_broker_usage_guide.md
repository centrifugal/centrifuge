# Kafka Broker ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£æä¾› Kafka Broker çš„å®Œæ•´ä½¿ç”¨æŒ‡å—ï¼ŒåŒ…æ‹¬å®‰è£…é…ç½®ã€éƒ¨ç½²å®è·µã€ç›‘æ§è¿ç»´ç­‰å†…å®¹ã€‚

## ğŸ“‹ ç›®å½•

- [1. å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)
- [2. é…ç½®è¯¦è§£](#2-é…ç½®è¯¦è§£)
- [3. å†å²å­˜å‚¨é…ç½®](#3-å†å²å­˜å‚¨é…ç½®)
- [4. éƒ¨ç½²æŒ‡å—](#4-éƒ¨ç½²æŒ‡å—)
- [5. ç›‘æ§å’Œè¿ç»´](#5-ç›‘æ§å’Œè¿ç»´)
- [6. æ€§èƒ½è°ƒä¼˜](#6-æ€§èƒ½è°ƒä¼˜)
- [7. æ•…éšœæ’æŸ¥](#7-æ•…éšœæ’æŸ¥)
- [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)

## 1. å¿«é€Ÿå¼€å§‹

### 1.1 åŸºæœ¬ç¤ºä¾‹

```go
package main

import (
    "log"
    "os"
    "os/signal"
    "syscall"
    
    "github.com/channelwill/cw2-live-chat-common/pkg/broker/gkafka"
    "github.com/channelwill/cw2-live-chat-common/pkg/storage/gredis"
    centrifuge "github.com/channelwill/cw2-live-chat-centrifuge"
)

func main() {
    // 1. åˆ›å»º Centrifuge Node
    node, err := centrifuge.New(centrifuge.Config{
        LogLevel:   centrifuge.LogLevelInfo,
        LogHandler: func(entry centrifuge.LogEntry) {
            log.Printf("[%s] %s", entry.Level, entry.Message)
        },
    })
    if err != nil {
        log.Fatal("Failed to create node:", err)
    }

    // 2. é…ç½® Kafka Broker
    kafkaConfig := centrifuge.KafkaBrokerConfig{
        KafkaConfig: gkafka.KafkaConfig{
            Brokers: []string{"localhost:9092"},
        },
        TopicPrefix:     "livechat",
        ConsumerGroupID: "livechat-node-" + node.ID(),
        Name:           "production-kafka-broker",
    }

    // 3. åˆ›å»ºå¹¶è®¾ç½® Broker
    broker, err := centrifuge.NewKafkaBroker(node, kafkaConfig)
    if err != nil {
        log.Fatal("Failed to create Kafka broker:", err)
    }

    node.SetBroker(broker)

    // 4. å¯åŠ¨æœåŠ¡
    if err := node.Run(); err != nil {
        log.Fatal("Failed to run node:", err)
    }

    // 5. ä¼˜é›…é€€å‡º
    waitExitSignal()
    
    log.Println("Shutting down...")
    _ = node.Shutdown()
}

func waitExitSignal() {
    sigCh := make(chan os.Signal, 1)
    signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
    <-sigCh
}
```

### 1.2 Docker Compose å¿«é€Ÿå¯åŠ¨

```yaml
# docker-compose.yml
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru

  livechat:
    build: .
    depends_on:
      - kafka
      - redis
    ports:
      - "8000:8000"
    environment:
      KAFKA_BROKERS: "kafka:9092"
      REDIS_URL: "redis:6379"
```

## 2. é…ç½®è¯¦è§£

### 2.1 KafkaBrokerConfig å®Œæ•´é…ç½®

```go
type KafkaBrokerConfig struct {
    // === Kafka é…ç½®ï¼ˆåŸºäº Common åŒ…ï¼‰===
    KafkaConfig gkafka.KafkaConfig {
        // åŸºç¡€è¿æ¥é…ç½®
        Brokers              []string      // Kafka broker åœ°å€åˆ—è¡¨
        Username             string        // SASL ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
        Password             string        // SASL å¯†ç ï¼ˆå¯é€‰ï¼‰
        
        // å®‰å…¨é…ç½®
        SecurityProtocol     string        // å®‰å…¨åè®®ï¼šPLAINTEXT, SASL_PLAINTEXT, SASL_SSL, SSL
        SASLMechanism        string        // SASL æœºåˆ¶ï¼šPLAIN, SCRAM-SHA-256, SCRAM-SHA-512
        SASLTypeSCRAMSHA     string        // SCRAM ç±»å‹
        CACertPath           string        // CA è¯ä¹¦è·¯å¾„
        
        // æ€§èƒ½é…ç½®
        Version              string        // Kafka ç‰ˆæœ¬
        DialTimeout          time.Duration // è¿æ¥è¶…æ—¶
        ProducerTimeout      time.Duration // ç”Ÿäº§è€…è¶…æ—¶
        ProducerRetryMax     int           // ç”Ÿäº§è€…é‡è¯•æ¬¡æ•°
        ProducerMaxMessageBytes int        // å•æ¡æ¶ˆæ¯æœ€å¤§å­—èŠ‚æ•°
        
        // æ¶ˆè´¹è€…é…ç½®
        ConsumerAutoCommitInterval time.Duration // è‡ªåŠ¨æäº¤é—´éš”
        ConsumerOffsetsInitial     int64         // åˆå§‹ offsetï¼š-1(newest), -2(oldest)
        
        // ä¼˜é›…å…³é—­
        GracefulWait         time.Duration // ä¼˜é›…å…³é—­ç­‰å¾…æ—¶é—´
    }
    
    // === Centrifuge ç‰¹æœ‰é…ç½® ===
    TopicPrefix          string           // Topic å‰ç¼€ï¼Œé»˜è®¤ "centrifuge"
    ConsumerGroupID      string           // æ¶ˆè´¹è€…ç»„ IDï¼Œé»˜è®¤ "centrifuge-node-{nodeID}"
    Name                string           // Broker åç§°ï¼Œç”¨äºæ—¥å¿—æ ‡è¯†
    NumPartitions       int              // Topic åˆ†åŒºæ•°ï¼Œé»˜è®¤ 1
    
    // === å†å²å­˜å‚¨é…ç½® ===
    HistoryStorage      HistoryStorage   // å†å²å­˜å‚¨å®ç°ï¼Œé»˜è®¤ MemoryHistoryStorage
}
```

### 2.2 ç¯å¢ƒå˜é‡é…ç½®

```bash
# Kafka é…ç½®
export KAFKA_BROKERS="broker1:9092,broker2:9092,broker3:9092"
export KAFKA_USERNAME="your-username"
export KAFKA_PASSWORD="your-password"
export KAFKA_SECURITY_PROTOCOL="SASL_SSL"
export KAFKA_SASL_MECHANISM="SCRAM-SHA-256"

# Centrifuge é…ç½®
export CENTRIFUGE_TOPIC_PREFIX="production"
export CENTRIFUGE_CONSUMER_GROUP="livechat-prod"

# Redis é…ç½®ï¼ˆå†å²å­˜å‚¨ï¼‰
export REDIS_URL="redis-cluster.example.com:6379"
export REDIS_PASSWORD="your-redis-password"
export REDIS_DB="0"
```

```go
// ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
func loadConfigFromEnv() centrifuge.KafkaBrokerConfig {
    kafkaConfig := gkafka.KafkaConfig{
        Brokers:          strings.Split(os.Getenv("KAFKA_BROKERS"), ","),
        Username:         os.Getenv("KAFKA_USERNAME"),
        Password:         os.Getenv("KAFKA_PASSWORD"),
        SecurityProtocol: os.Getenv("KAFKA_SECURITY_PROTOCOL"),
        SASLMechanism:    os.Getenv("KAFKA_SASL_MECHANISM"),
    }
    
    return centrifuge.KafkaBrokerConfig{
        KafkaConfig:     kafkaConfig,
        TopicPrefix:     getEnvOrDefault("CENTRIFUGE_TOPIC_PREFIX", "centrifuge"),
        ConsumerGroupID: getEnvOrDefault("CENTRIFUGE_CONSUMER_GROUP", ""),
        Name:           getEnvOrDefault("CENTRIFUGE_BROKER_NAME", "kafka-broker"),
    }
}

func getEnvOrDefault(key, defaultValue string) string {
    if value := os.Getenv(key); value != "" {
        return value
    }
    return defaultValue
}
```

## 3. å†å²å­˜å‚¨é…ç½®

### 3.1 Redis å†å²å­˜å‚¨ï¼ˆæ¨èï¼‰

```go
// é…ç½® Redis å†å²å­˜å‚¨
func setupRedisHistoryStorage() centrifuge.HistoryStorage {
    redisConf := gredis.RedisConf{
        Address:         os.Getenv("REDIS_URL"),
        Password:        os.Getenv("REDIS_PASSWORD"),
        DB:              0,
        PoolSize:        20,
        DialTimeout:     5 * time.Second,
        ReadTimeout:     3 * time.Second,
        WriteTimeout:    3 * time.Second,
        PoolTimeout:     4 * time.Second,
        ConnMaxLifetime: 30 * time.Minute,
        ConnMaxIdleTime: 5 * time.Minute,
    }
    
    return centrifuge.NewRedisHistoryStorageFromConf(redisConf, "livechat")
}

// é›†æˆåˆ° Kafka Broker
kafkaConfig := centrifuge.KafkaBrokerConfig{
    KafkaConfig:    kafkaConfig,
    HistoryStorage: setupRedisHistoryStorage(), // ä½¿ç”¨ Redis å­˜å‚¨
}
```

### 3.2 å†…å­˜å†å²å­˜å‚¨ï¼ˆå¼€å‘/æµ‹è¯•ï¼‰

```go
// ä½¿ç”¨é»˜è®¤å†…å­˜å­˜å‚¨ï¼ˆæ— éœ€é¢å¤–é…ç½®ï¼‰
kafkaConfig := centrifuge.KafkaBrokerConfig{
    KafkaConfig: kafkaConfig,
    // HistoryStorage ç•™ç©ºï¼Œè‡ªåŠ¨ä½¿ç”¨ MemoryHistoryStorage
}

// æˆ–è€…æ˜¾å¼åˆ›å»º
kafkaConfig := centrifuge.KafkaBrokerConfig{
    KafkaConfig:    kafkaConfig,
    HistoryStorage: centrifuge.NewMemoryHistoryStorage(),
}
```

### 3.3 è‡ªå®šä¹‰å†å²å­˜å‚¨

```go
// å®ç°è‡ªå®šä¹‰å­˜å‚¨
type CustomHistoryStorage struct {
    // ä½ çš„å­˜å‚¨å®ç°
}

func (c *CustomHistoryStorage) AddToHistory(ctx context.Context, channel string, pub *centrifuge.Publication, opts centrifuge.PublishOptions) (centrifuge.StreamPosition, error) {
    // å®ç°æ·»åŠ å†å²æ¶ˆæ¯é€»è¾‘
    return centrifuge.StreamPosition{}, nil
}

func (c *CustomHistoryStorage) GetHistory(ctx context.Context, channel string, opts centrifuge.HistoryOptions) ([]*centrifuge.Publication, centrifuge.StreamPosition, error) {
    // å®ç°è·å–å†å²æ¶ˆæ¯é€»è¾‘
    return nil, centrifuge.StreamPosition{}, nil
}

func (c *CustomHistoryStorage) RemoveHistory(ctx context.Context, channel string) error {
    // å®ç°åˆ é™¤å†å²æ¶ˆæ¯é€»è¾‘
    return nil
}

// ä½¿ç”¨è‡ªå®šä¹‰å­˜å‚¨
kafkaConfig := centrifuge.KafkaBrokerConfig{
    KafkaConfig:    kafkaConfig,
    HistoryStorage: &CustomHistoryStorage{},
}
```

## 4. éƒ¨ç½²æŒ‡å—

### 4.1 Kubernetes éƒ¨ç½²

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: livechat-centrifuge
  labels:
    app: livechat-centrifuge
spec:
  replicas: 3  # 3 ä¸ªèŠ‚ç‚¹å®ä¾‹
  selector:
    matchLabels:
      app: livechat-centrifuge
  template:
    metadata:
      labels:
        app: livechat-centrifuge
    spec:
      containers:
      - name: centrifuge
        image: livechat/centrifuge:latest
        ports:
        - containerPort: 8000
        env:
        - name: KAFKA_BROKERS
          value: "kafka-cluster.kafka.svc.cluster.local:9092"
        - name: REDIS_URL
          value: "redis-cluster.redis.svc.cluster.local:6379"
        - name: CENTRIFUGE_TOPIC_PREFIX
          value: "livechat-prod"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

### 4.2 å¥åº·æ£€æŸ¥å®ç°

```go
func healthCheckHandler(w http.ResponseWriter, r *http.Request) {
    // æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€
    if !node.IsRunning() {
        http.Error(w, "Node not running", http.StatusServiceUnavailable)
        return
    }
    
    // æ£€æŸ¥ Redis è¿æ¥ï¼ˆå¦‚æœä½¿ç”¨ Redis å†å²å­˜å‚¨ï¼‰
    if redisStorage, ok := broker.GetHistoryStorage().(*centrifuge.RedisHistoryStorage); ok {
        if err := redisStorage.Health(context.Background()); err != nil {
            http.Error(w, "Redis unhealthy", http.StatusServiceUnavailable)
            return
        }
    }
    
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}
```

## 5. ç›‘æ§å’Œè¿ç»´

### 5.1 æ—¥å¿—é…ç½®

```go
// ç»“æ„åŒ–æ—¥å¿—é…ç½®
node, err := centrifuge.New(centrifuge.Config{
    LogLevel: centrifuge.LogLevelInfo,
    LogHandler: func(entry centrifuge.LogEntry) {
        // ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—åº“ï¼ˆå¦‚ zap, logrusï¼‰
        logger.WithFields(map[string]interface{}{
            "level":     entry.Level.String(),
            "message":   entry.Message,
            "fields":    entry.Fields,
            "timestamp": time.Now(),
            "service":   "centrifuge",
        }).Info("centrifuge log")
    },
})
```

### 5.2 Prometheus ç›‘æ§æŒ‡æ ‡

```go
import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // æ¶ˆæ¯å‘å¸ƒæŒ‡æ ‡
    publishedMessages = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "centrifuge_published_messages_total",
            Help: "The total number of published messages",
        },
        []string{"channel", "status"},
    )
    
    // è¿æ¥æ•°æŒ‡æ ‡
    activeConnections = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "centrifuge_active_connections",
            Help: "The number of active connections",
        },
    )
)

// å¯åŠ¨ Prometheus æŒ‡æ ‡æœåŠ¡
func startMetricsServer() {
    http.Handle("/metrics", promhttp.Handler())
    go func() {
        log.Fatal(http.ListenAndServe(":9090", nil))
    }()
}
```

## 6. æ€§èƒ½è°ƒä¼˜

### 6.1 Kafka é…ç½®è°ƒä¼˜

```go
kafkaConfig := gkafka.KafkaConfig{
    Brokers: []string{"localhost:9092"},
    
    // ç”Ÿäº§è€…æ€§èƒ½ä¼˜åŒ–
    ProducerTimeout:          5 * time.Second,     // å‘é€è¶…æ—¶
    ProducerRetryMax:         3,                   // é‡è¯•æ¬¡æ•°
    ProducerMaxMessageBytes:  1024 * 1024,         // 1MB æœ€å¤§æ¶ˆæ¯å¤§å°
    
    // æ¶ˆè´¹è€…é…ç½®
    ConsumerAutoCommitInterval: time.Second,       // è‡ªåŠ¨æäº¤é—´éš”
    ConsumerOffsetsInitial:     -1,               // ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
    
    // è¿æ¥ä¼˜åŒ–
    DialTimeout:              10 * time.Second,    // è¿æ¥è¶…æ—¶
}
```

### 6.2 Redis å†å²å­˜å‚¨è°ƒä¼˜

```go
redisConf := gredis.RedisConf{
    Address:  "localhost:6379",
    Password: "",
    DB:       0,
    
    // è¿æ¥æ± ä¼˜åŒ–
    PoolSize:        runtime.NumCPU() * 4,    // è¿æ¥æ± å¤§å°
    PoolTimeout:     4 * time.Second,         // è·å–è¿æ¥è¶…æ—¶
    ConnMaxLifetime: 30 * time.Minute,        // è¿æ¥æœ€å¤§ç”Ÿå‘½å‘¨æœŸ
    ConnMaxIdleTime: 5 * time.Minute,         // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
    
    // è¯»å†™è¶…æ—¶ä¼˜åŒ–
    DialTimeout:  5 * time.Second,            // è¿æ¥è¶…æ—¶
    ReadTimeout:  3 * time.Second,            // è¯»å–è¶…æ—¶
    WriteTimeout: 3 * time.Second,            // å†™å…¥è¶…æ—¶
}
```

## 7. æ•…éšœæ’æŸ¥

### 7.1 å¸¸è§é—®é¢˜è¯Šæ–­

#### Kafka è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥ Kafka è¿æ¥
kubectl exec -it <pod-name> -- telnet kafka-broker 9092

# æŸ¥çœ‹ Kafka topic
kafka-topics --bootstrap-server localhost:9092 --list

# æŸ¥çœ‹æ¶ˆè´¹è€…ç»„çŠ¶æ€
kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group livechat-node-xxx
```

#### Redis è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥ Redis è¿æ¥
redis-cli -h redis-host -p 6379 ping

# æŸ¥çœ‹ Redis å†…å­˜ä½¿ç”¨
redis-cli info memory

# æŸ¥çœ‹å†å²æ¶ˆæ¯å­˜å‚¨
redis-cli XLEN livechat:history:stream:chat:room:123
```

### 7.2 å…³é”®é”™è¯¯æ—¥å¿—

```go
// å¸¸è§é”™è¯¯æ¨¡å¼
const (
    "kafka broker global consumer failed"     // Kafka æ¶ˆè´¹è€…è¿æ¥å¤±è´¥
    "failed to add to history"                // å†å²æ¶ˆæ¯å­˜å‚¨å¤±è´¥
    "failed to unmarshal kafka message"       // æ¶ˆæ¯è§£æå¤±è´¥
    "failed to handle publication"            // æ¶ˆæ¯å¤„ç†å¤±è´¥
)
```

## 8. æœ€ä½³å®è·µ

### 8.1 ç”Ÿäº§ç¯å¢ƒé…ç½®

```go
// ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®
func productionConfig() centrifuge.KafkaBrokerConfig {
    return centrifuge.KafkaBrokerConfig{
        KafkaConfig: gkafka.KafkaConfig{
            Brokers: strings.Split(os.Getenv("KAFKA_BROKERS"), ","),
            
            // å®‰å…¨é…ç½®
            Username:         os.Getenv("KAFKA_USERNAME"),
            Password:         os.Getenv("KAFKA_PASSWORD"),
            SecurityProtocol: "SASL_SSL",
            SASLMechanism:    "SCRAM-SHA-256",
            
            // æ€§èƒ½é…ç½®
            ProducerTimeout:          5 * time.Second,
            ProducerRetryMax:         3,
            ProducerMaxMessageBytes:  1024 * 1024,
            
            // æ¶ˆè´¹è€…é…ç½®
            ConsumerAutoCommitInterval: time.Second,
            ConsumerOffsetsInitial:     -1, // ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
        },
        
        // Centrifuge é…ç½®
        TopicPrefix:     "production",
        ConsumerGroupID: "", // è‡ªåŠ¨ç”Ÿæˆ
        Name:           "production-kafka-broker",
        NumPartitions:   3,  // æ ¹æ®è´Ÿè½½è°ƒæ•´
        
        // ä½¿ç”¨ Redis å†å²å­˜å‚¨
        HistoryStorage: setupRedisHistoryStorage(),
    }
}
```

### 8.2 é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```go
// ä¼˜é›…é”™è¯¯å¤„ç†
func (b *KafkaBroker) PublishWithRetry(ch string, data []byte, opts PublishOptions) (StreamPosition, bool, error) {
    const maxRetries = 3
    const baseDelay = 100 * time.Millisecond
    
    for attempt := 0; attempt < maxRetries; attempt++ {
        sp, suppressed, err := b.Publish(ch, data, opts)
        if err == nil {
            return sp, suppressed, nil
        }
        
        if attempt < maxRetries-1 {
            // æŒ‡æ•°é€€é¿
            delay := baseDelay * time.Duration(1<<attempt)
            time.Sleep(delay)
        }
    }
    
    return StreamPosition{}, false, fmt.Errorf("failed to publish after %d attempts", maxRetries)
}
```

### 8.3 éƒ¨ç½²æ£€æŸ¥æ¸…å•

- âœ… **ç¯å¢ƒé…ç½®**ï¼šç¡®è®¤æ‰€æœ‰ç¯å¢ƒå˜é‡æ­£ç¡®è®¾ç½®
- âœ… **ç½‘ç»œè¿é€šæ€§**ï¼šéªŒè¯åˆ° Kafka å’Œ Redis çš„ç½‘ç»œè¿æ¥
- âœ… **èµ„æºé…é¢**ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„ CPU å’Œå†…å­˜èµ„æº
- âœ… **å¥åº·æ£€æŸ¥**ï¼šé…ç½® liveness å’Œ readiness æ¢é’ˆ
- âœ… **ç›‘æ§æŒ‡æ ‡**ï¼šå¯ç”¨ Prometheus æŒ‡æ ‡æ”¶é›†
- âœ… **æ—¥å¿—æ”¶é›†**ï¼šé…ç½®ç»“æ„åŒ–æ—¥å¿—è¾“å‡º
- âœ… **å®‰å…¨è®¤è¯**ï¼šå¯ç”¨ Kafka å’Œ Redis è®¤è¯
- âœ… **å¤‡ä»½ç­–ç•¥**ï¼šåˆ¶å®š Redis æ•°æ®å¤‡ä»½è®¡åˆ’

## æ€»ç»“

æœ¬ä½¿ç”¨æŒ‡å—æä¾›äº† Kafka Broker ä»å¼€å‘åˆ°ç”Ÿäº§çš„å®Œæ•´éƒ¨ç½²æµç¨‹ã€‚å…³é”®è¦ç‚¹ï¼š

### ğŸ”§ **é…ç½®è¦ç‚¹**
- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†é…ç½®
- ç”Ÿäº§ç¯å¢ƒå¯ç”¨å®‰å…¨è®¤è¯
- åˆç†é…ç½®è¿æ¥æ± å’Œè¶…æ—¶å‚æ•°

### ğŸš€ **éƒ¨ç½²è¦ç‚¹**
- ä½¿ç”¨ Redis å†å²å­˜å‚¨æå‡åˆ†å¸ƒå¼ä¸€è‡´æ€§
- é…ç½®å¥åº·æ£€æŸ¥å’Œä¼˜é›…å…³é—­
- åˆç†è®¾ç½®èµ„æºé™åˆ¶å’Œç›‘æ§æŒ‡æ ‡

### ğŸ“Š **è¿ç»´è¦ç‚¹**
- å»ºç«‹å®Œå–„çš„ç›‘æ§å’Œå‘Šè­¦ä½“ç³»
- å®šæœŸæ£€æŸ¥ Kafka å’Œ Redis é›†ç¾¤çŠ¶æ€
- åˆ¶å®šæ•…éšœåº”æ€¥é¢„æ¡ˆ

æŒ‰ç…§æœ¬æŒ‡å—å¯ä»¥æ„å»ºç¨³å®šã€é«˜æ€§èƒ½çš„åˆ†å¸ƒå¼å®æ—¶é€šä¿¡ç³»ç»Ÿï¼ 