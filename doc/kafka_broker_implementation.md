# Kafka Broker å®ç°åŸç†æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸºäº Kafka çš„ Centrifuge Broker å®ç°åŸç†ã€æ¶æ„è®¾è®¡å’Œæ ¸å¿ƒæœºåˆ¶ã€‚

## ğŸ“‹ ç›®å½•

- [1. æ€»ä½“æ¶æ„](#1-æ€»ä½“æ¶æ„)
- [2. æ ¸å¿ƒè®¾è®¡ç†å¿µ](#2-æ ¸å¿ƒè®¾è®¡ç†å¿µ)
- [3. æ¶ˆæ¯éš”ç¦»æœºåˆ¶](#3-æ¶ˆæ¯éš”ç¦»æœºåˆ¶)
- [4. æ ¸å¿ƒç»„ä»¶](#4-æ ¸å¿ƒç»„ä»¶)
- [5. æ¶ˆæ¯æµè½¬æœºåˆ¶](#5-æ¶ˆæ¯æµè½¬æœºåˆ¶)
- [6. å†å²å­˜å‚¨è®¾è®¡](#6-å†å²å­˜å‚¨è®¾è®¡)
- [7. è®¢é˜…ç®¡ç†æœºåˆ¶](#7-è®¢é˜…ç®¡ç†æœºåˆ¶)
- [8. é”™è¯¯å¤„ç†å’Œé‡è¯•](#8-é”™è¯¯å¤„ç†å’Œé‡è¯•)
- [9. æ€§èƒ½ä¼˜åŒ–è®¾è®¡](#9-æ€§èƒ½ä¼˜åŒ–è®¾è®¡)
- [10. ä¸ Redis Broker å¯¹æ¯”](#10-ä¸-redis-broker-å¯¹æ¯”)

## 1. æ€»ä½“æ¶æ„

### 1.1 æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "Centrifuge Nodes"
        N1[Node 1]
        N2[Node 2] 
        N3[Node 3]
    end
    
    subgraph "Kafka Unified Topic"
        UT[centrifuge.messages]
        P1[Partition 1<br/>channel-a messages]
        P2[Partition 2<br/>channel-b messages]
        P3[Partition 3<br/>channel-c messages]
        
        UT --> P1
        UT --> P2
        UT --> P3
    end
    
    subgraph "History Storage"
        RS[Redis Streams]
        MS[Memory Storage]
    end
    
    N1 --> UT
    N2 --> UT
    N3 --> UT
    
    N1 -.-> RS
    N2 -.-> RS
    N3 -.-> RS
    
    N1 -.-> MS
    N2 -.-> MS
    N3 -.-> MS
```

### 1.2 è®¾è®¡åŸåˆ™

| åŸåˆ™             | å®ç°æ–¹å¼                      | ä¼˜åŠ¿                           |
| ---------------- | ----------------------------- | ------------------------------ |
| **é€»è¾‘éš”ç¦»**     | ç»Ÿä¸€ topic + åº”ç”¨å±‚è®¢é˜…æ£€æŸ¥   | å‡å°‘è¿æ¥æ•°ï¼Œå®ç° channel éš”ç¦»  |
| **æ¶ˆæ¯æœ‰åºæ€§**   | channel ä½œä¸ºåˆ†åŒºé”®            | ä¿è­‰åŒä¸€ channel å†…æ¶ˆæ¯æœ‰åº    |
| **èµ„æºæœ€ä¼˜åŒ–**   | å•ä¸€æ¶ˆè´¹è€… + å†…å­˜è·¯ç”±è¡¨       | æœ€å°åŒ– Kafka è¿æ¥å’Œ topic æ•°é‡ |
| **åˆ†å¸ƒå¼ä¸€è‡´æ€§** | å¯æ’æ‹”å†å²å­˜å‚¨æ¥å£            | æ”¯æŒ Redis/Memory ç­‰å¤šç§å­˜å‚¨   |
| **é«˜å¯ç”¨æ€§**     | åŸºäº Common åŒ…çš„ Kafka å®¢æˆ·ç«¯ | è‡ªåŠ¨é‡è¿ã€é”™è¯¯é‡è¯•             |
| **å¯è§‚æµ‹æ€§**     | å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§æ¥å£          | ä¾¿äºè¿ç»´å’Œé—®é¢˜æ’æŸ¥             |

## 2. æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 2.1 "ç»Ÿä¸€æ¶ˆæ¯æµ + é€»è¾‘éš”ç¦»" è®¾è®¡æ¨¡å¼

**æ ¸å¿ƒç†å¿µ**ï¼šåœ¨ç‰©ç†å±‚é¢ä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯ä¼ è¾“é€šé“ï¼Œåœ¨åº”ç”¨å±‚é¢å®ç°é€»è¾‘éš”ç¦»

```go
// ç‰©ç†å±‚é¢ï¼šç»Ÿä¸€çš„ Kafka Topic
messagesTopic := "centrifuge.messages"

// é€»è¾‘å±‚é¢ï¼šé€šè¿‡è®¢é˜…æ£€æŸ¥å®ç°éš”ç¦»
if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
    return nil // å¿½ç•¥æœªè®¢é˜…çš„ channel æ¶ˆæ¯
}
```

### 2.2 è®¾è®¡ä¼˜åŠ¿å¯¹æ¯”

| è®¾è®¡æ¨¡å¼             | ä¼ ç»Ÿè®¾è®¡ (æ¯ channel ä¸€ä¸ª topic) | å½“å‰è®¾è®¡ (ç»Ÿä¸€ topic + é€»è¾‘éš”ç¦») |
| -------------------- | -------------------------------- | -------------------------------- |
| **Kafka Topic æ•°é‡** | N channels = N topics            | N channels = 1 topic             |
| **Kafka è¿æ¥æ•°**     | N channels = N consumers         | N channels = 1 consumer          |
| **èµ„æºæ¶ˆè€—**         | é«˜ (çº¿æ€§å¢é•¿)                    | ä½ (å¸¸æ•°çº§åˆ«)                    |
| **æ¶ˆæ¯æœ‰åºæ€§**       | âœ… å¤©ç„¶ä¿è¯                       | âœ… é€šè¿‡åˆ†åŒºé”®ä¿è¯                 |
| **éš”ç¦»æ€§**           | âœ… ç‰©ç†éš”ç¦»                       | âœ… é€»è¾‘éš”ç¦»                       |
| **å¯æ‰©å±•æ€§**         | âŒ å— Kafka topic é™åˆ¶            | âœ… å‡ ä¹æ— é™æ‰©å±•                   |
| **è¿ç»´å¤æ‚åº¦**       | é«˜ (ç®¡ç†å¤§é‡ topic)              | ä½ (ç®¡ç†å•ä¸€ topic)              |

## 3. æ¶ˆæ¯éš”ç¦»æœºåˆ¶

### 3.1 éš”ç¦»æœºåˆ¶æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph "å‘é€ç«¯éš”ç¦»"
        S1[Channel A æ¶ˆæ¯] 
        S2[Channel B æ¶ˆæ¯]
        S3[Channel C æ¶ˆæ¯]
    end
    
    subgraph "Kafka ç»Ÿä¸€ Topic"
        UT[centrifuge.messages]
        P1[Partition 1]
        P2[Partition 2] 
        P3[Partition 3]
    end
    
    subgraph "æ¥æ”¶ç«¯éš”ç¦»"
        GC[å…¨å±€æ¶ˆè´¹è€…]
        R1[Channel A è®¢é˜…æ£€æŸ¥]
        R2[Channel B è®¢é˜…æ£€æŸ¥]
        R3[Channel C è®¢é˜…æ£€æŸ¥]
        
        H1[Channel A å¤„ç†å™¨]
        H2[Channel B å¤„ç†å™¨]
        H3[Channel C å¤„ç†å™¨]
    end
    
    S1 -->|åˆ†åŒºé”®:A| P1
    S2 -->|åˆ†åŒºé”®:B| P2  
    S3 -->|åˆ†åŒºé”®:C| P3
    
    P1 --> UT
    P2 --> UT
    P3 --> UT
    
    UT --> GC
    
    GC --> R1
    GC --> R2
    GC --> R3
    
    R1 -->|å·²è®¢é˜…| H1
    R2 -->|å·²è®¢é˜…| H2
    R3 -->|æœªè®¢é˜…| X[å¿½ç•¥æ¶ˆæ¯]
```

### 3.2 éš”ç¦»å®ç°çš„å…³é”®ä»£ç 

**å‘é€ç«¯éš”ç¦» - åˆ†åŒºç­–ç•¥**ï¼š
```go
func (b *KafkaBroker) Publish(ch string, data []byte, opts PublishOptions) (StreamPosition, bool, error) {
    // åŒ…è£…æ¶ˆæ¯ï¼Œæ·»åŠ  channel ä¿¡æ¯
    msgWrapper := KafkaMessage{
        Type:           MessageTypePublication,
        Channel:        ch,                    // å…³é”®ï¼šchannel ä¿¡æ¯
        Data:           byteMessage,
        StreamPosition: sp,
    }

    // å‘å¸ƒåˆ°ç»Ÿä¸€ topicï¼Œä½¿ç”¨ channel ä½œä¸ºåˆ†åŒºé”®
    err = b.kafkaBroker.Publish(
        context.Background(),
        b.messagesTopic,                       // ç»Ÿä¸€ topic
        msgData,
        commonBroker.WithPublishName(ch),      // å…³é”®ï¼šchannel ä½œä¸ºåˆ†åŒºé”®
    )
    
    return sp, false, err
}
```

**æ¥æ”¶ç«¯éš”ç¦» - è®¢é˜…æ£€æŸ¥**ï¼š
```go
func (b *KafkaBroker) handleMessage(ctx context.Context, data []byte) error {
    // 1. è§£ææ¶ˆæ¯åŒ…è£…å™¨
    var msgWrapper KafkaMessage
    if err := json.Unmarshal(data, &msgWrapper); err != nil {
        return err
    }

    // 2. å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦è®¢é˜…äº†è¯¥ channel
    if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
        return nil // éš”ç¦»æœºåˆ¶ï¼šå¿½ç•¥æœªè®¢é˜…çš„ channel æ¶ˆæ¯
    }

    // 3. åªå¤„ç†å·²è®¢é˜…çš„æ¶ˆæ¯
    switch msgWrapper.Type {
    case MessageTypePublication:
        return b.handlePublication(msgWrapper)
    case MessageTypeJoin:
        return b.handleJoin(msgWrapper)
    case MessageTypeLeave:
        return b.handleLeave(msgWrapper)
    }
}
```

### 3.3 éš”ç¦»æœºåˆ¶çš„æ ¸å¿ƒç‰¹ç‚¹

| ç‰¹ç‚¹         | å®ç°æ–¹å¼                            | æ•ˆæœ                        |
| ------------ | ----------------------------------- | --------------------------- |
| **å‘é€éš”ç¦»** | channel ä½œä¸º Kafka åˆ†åŒºé”®           | åŒä¸€ channel æ¶ˆæ¯æœ‰åº       |
| **æ¥æ”¶éš”ç¦»** | è®¢é˜…è¡¨æ£€æŸ¥ (`subscriptions.Load()`) | åªå¤„ç†å·²è®¢é˜…çš„ channel æ¶ˆæ¯ |
| **çŠ¶æ€ç®¡ç†** | `sync.Map` ç®¡ç†è®¢é˜…çŠ¶æ€             | é«˜å¹¶å‘ã€æ— é”è¯»å†™            |
| **æ¶ˆæ¯è·¯ç”±** | åº”ç”¨å±‚æ¶ˆæ¯ç±»å‹è·¯ç”±                  | æ”¯æŒ Publication/Join/Leave |
| **æ•…éšœéš”ç¦»** | å•ä¸ª channel é”™è¯¯ä¸å½±å“å…¶ä»– channel | æé«˜ç³»ç»Ÿæ•´ä½“ç¨³å®šæ€§          |

## 4. æ ¸å¿ƒç»„ä»¶

### 4.1 ç»„ä»¶å…³ç³»å›¾

```go
// æ ¸å¿ƒç»„ä»¶ç»“æ„
type KafkaBroker struct {
    node           *Node                    // Centrifuge èŠ‚ç‚¹å¼•ç”¨
    config         KafkaBrokerConfig        // é…ç½®ä¿¡æ¯
    kafkaBroker    commonBroker.Broker      // Common åŒ… Kafka å®¢æˆ·ç«¯
    eventHandler   BrokerEventHandler       // äº‹ä»¶å¤„ç†å™¨
    
    // éš”ç¦»æœºåˆ¶æ ¸å¿ƒç»„ä»¶
    subscriptions  sync.Map                 // è®¢é˜…çŠ¶æ€è¡¨ï¼šmap[string]bool
    messagesTopic  string                   // ç»Ÿä¸€æ¶ˆæ¯ topic
    
    // å†å²å­˜å‚¨
    historyStorage HistoryStorage           // å†å²å­˜å‚¨æ¥å£
    
    // è®¢é˜…çŠ¶æ€ç®¡ç†
    subscriptionMu     sync.RWMutex         // è®¢é˜…é”
    isSubscribed       bool                 // å…¨å±€è®¢é˜…çŠ¶æ€
    subscribedChannels map[string]bool      // å·²è®¢é˜… channel åˆ—è¡¨
    
    // ç”Ÿå‘½å‘¨æœŸç®¡ç†
    closeOnce      sync.Once               // ç¡®ä¿åªå…³é—­ä¸€æ¬¡
    stopCh         chan struct{}           // åœæ­¢ä¿¡å·
    
    // Topic ç®¡ç†
    adminClient    sarama.ClusterAdmin     // ç”¨äº topic è‡ªåŠ¨åˆ›å»º
}
```

### 4.2 é…ç½®ç»„ä»¶

```go
type KafkaBrokerConfig struct {
    // Kafka é…ç½® - ç›´æ¥ä½¿ç”¨ Common åŒ…
    KafkaConfig gkafka.KafkaConfig
    
    // Centrifuge ç‰¹æœ‰é…ç½®
    TopicPrefix     string           // Topic å‰ç¼€ï¼Œé»˜è®¤ "centrifuge"
    ConsumerGroupID string           // æ¶ˆè´¹è€…ç»„ ID
    Name           string           // Broker åç§°ï¼Œç”¨äºæ—¥å¿—å’Œç›‘æ§
    
    // å†å²å­˜å‚¨é…ç½®
    HistoryStorage HistoryStorage   // å¯æ’æ‹”çš„å†å²å­˜å‚¨
    
    // æ€§èƒ½å’Œéš”ç¦»é…ç½®
    NumPartitions     int            // Topic åˆ†åŒºæ•°ï¼Œå½±å“éš”ç¦»ç²’åº¦
    ReplicationFactor int16          // å‰¯æœ¬å› å­ï¼Œé»˜è®¤ 1
    RetentionHours    int            // æ¶ˆæ¯ä¿ç•™æ—¶é—´ï¼Œé»˜è®¤ 24 å°æ—¶
    AutoCreateTopic   bool           // æ˜¯å¦è‡ªåŠ¨åˆ›å»º topicï¼Œé»˜è®¤ true
}
```

## 5. æ¶ˆæ¯æµè½¬æœºåˆ¶

### 5.1 æ¶ˆæ¯ç»Ÿä¸€åŒ–è®¾è®¡

**å…³é”®åˆ›æ–°**ï¼šæ‰€æœ‰æ¶ˆæ¯ç±»å‹éƒ½é€šè¿‡å•ä¸€ Kafka Topic ä¼ è¾“ï¼Œä½¿ç”¨æ¶ˆæ¯åŒ…è£…å™¨è¿›è¡Œç±»å‹åŒºåˆ†å’Œéš”ç¦»è·¯ç”±ã€‚

```go
// æ¶ˆæ¯åŒ…è£…å™¨ - éš”ç¦»æœºåˆ¶çš„æ ¸å¿ƒæ•°æ®ç»“æ„
type KafkaMessage struct {
    Type           MessageType    `json:"type"`            // æ¶ˆæ¯ç±»å‹è·¯ç”±
    Channel        string         `json:"channel"`         // éš”ç¦»æ ‡è¯†
    Data           []byte         `json:"data"`            // æ¶ˆæ¯æ•°æ® (protobuf)
    StreamPosition StreamPosition `json:"stream_position,omitempty"` // æµä½ç½®ä¿¡æ¯
}

// æ¶ˆæ¯ç±»å‹å®šä¹‰
const (
    MessageTypePublication MessageType = iota  // æ™®é€šæ¶ˆæ¯
    MessageTypeJoin                           // ç”¨æˆ·åŠ å…¥
    MessageTypeLeave                          // ç”¨æˆ·ç¦»å¼€
)
```

### 5.2 å‘å¸ƒæµç¨‹ï¼ˆå¸¦éš”ç¦»æœºåˆ¶ï¼‰

```mermaid
sequenceDiagram
    participant C as Client
    participant N as Node
    participant KB as KafkaBroker
    participant HS as HistoryStorage
    participant K as Kafka Topic
    participant P as Partition

    C->>N: Publish Message to Channel A
    N->>KB: Publish(channel="A", data, opts)
    
    KB->>KB: åˆ›å»ºæ¶ˆæ¯åŒ…è£…å™¨<br/>(æ·»åŠ  channel æ ‡è¯†)
    
    alt History Enabled
        KB->>HS: AddToHistory(channel="A", pub, opts)
        HS-->>KB: StreamPosition
    end
    
    KB->>K: Publish Message
    Note over KB,K: ä½¿ç”¨ channel="A" ä½œä¸ºåˆ†åŒºé”®
    K->>P: è·¯ç”±åˆ° Partition 1<br/>(åŸºäº channel="A")
    
    P-->>K: Success
    K-->>KB: Success  
    KB-->>N: StreamPosition
    N-->>C: Publish Result
```

### 5.3 æ¶ˆè´¹å¤„ç†æµç¨‹ï¼ˆéš”ç¦»æ£€æŸ¥ï¼‰

```mermaid
flowchart TD
    A[Kafka æ¶ˆæ¯åˆ°è¾¾] --> B{JSON è§£ææ¶ˆæ¯åŒ…è£…å™¨}
    B -->|Success| C{æå– Channel ä¿¡æ¯}
    B -->|Error| D[è®°å½•é”™è¯¯å¹¶è·³è¿‡]
    
    C --> E{æ£€æŸ¥è®¢é˜…çŠ¶æ€<br/>subscriptions.Load(channel)}
    
    E -->|å·²è®¢é˜…| F{æ¶ˆæ¯ç±»å‹è·¯ç”±}
    E -->|æœªè®¢é˜…| G[éš”ç¦»ï¼šå¿½ç•¥æ¶ˆæ¯]
    
    F -->|Publication| H[å¤„ç†å‘å¸ƒæ¶ˆæ¯]
    F -->|Join| I[å¤„ç†åŠ å…¥äº‹ä»¶]
    F -->|Leave| J[å¤„ç†ç¦»å¼€äº‹ä»¶]
    
    H --> K[è°ƒç”¨ EventHandler]
    I --> K
    J --> K
    
    K --> L[å¤„ç†å®Œæˆ]
    D --> L
    G --> L
    
    style E fill:#e1f5fe
    style G fill:#ffebee
```

**ç»Ÿä¸€æ¶ˆæ¯å¤„ç†å™¨çš„éš”ç¦»é€»è¾‘**ï¼š
```go
func (b *KafkaBroker) handleMessage(ctx context.Context, data []byte) error {
    if b.eventHandler == nil {
        return nil
    }

    // 1. è§£ææ¶ˆæ¯åŒ…è£…å™¨ï¼Œè·å– channel ä¿¡æ¯
    var msgWrapper KafkaMessage
    if err := json.Unmarshal(data, &msgWrapper); err != nil {
        b.node.logger.log(newErrorLogEntry(err, "failed to unmarshal message", nil))
        return nil // é”™è¯¯æ¶ˆæ¯ä¸ä¸­æ–­æ•´ä½“æ¶ˆè´¹
    }

    // 2. éš”ç¦»æœºåˆ¶æ ¸å¿ƒï¼šè®¢é˜…çŠ¶æ€æ£€æŸ¥
    if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
        // å…³é”®éš”ç¦»ç‚¹ï¼šæœªè®¢é˜…çš„ channel ï¼Œç›´æ¥å¿½ç•¥
        if b.node.logEnabled(LogLevelTrace) {
            b.node.logger.log(newLogEntry(LogLevelTrace, "ignoring message for unsubscribed channel", map[string]any{
                "channel": msgWrapper.Channel,
                "type":    msgWrapper.Type,
            }))
        }
        return nil
    }

    // 3. å·²è®¢é˜…çš„æ¶ˆæ¯ï¼Œæ ¹æ®ç±»å‹è·¯ç”±å¤„ç†
    switch msgWrapper.Type {
    case MessageTypePublication:
        return b.handlePublication(msgWrapper)
    case MessageTypeJoin:
        return b.handleJoin(msgWrapper)
    case MessageTypeLeave:
        return b.handleLeave(msgWrapper)
    default:
        return fmt.Errorf("unknown message type: %d", msgWrapper.Type)
    }
}
```

## 6. å†å²å­˜å‚¨è®¾è®¡

### 6.1 å¯æ’æ‹”å­˜å‚¨æ¶æ„

```go
// å†å²å­˜å‚¨æ¥å£ - ä¸éš”ç¦»æœºåˆ¶è§£è€¦
type HistoryStorage interface {
    AddToHistory(ctx context.Context, channel string, pub *Publication, opts PublishOptions) (StreamPosition, error)
    GetHistory(ctx context.Context, channel string, opts HistoryOptions) ([]*Publication, StreamPosition, error)
    RemoveHistory(ctx context.Context, channel string) error
}
```

### 6.2 å­˜å‚¨å®ç°å¯¹æ¯”

| å­˜å‚¨ç±»å‹                 | éš”ç¦»ç‰¹æ€§                     | é€‚ç”¨åœºæ™¯             | ä¼˜åŠ¿                         | åŠ£åŠ¿                     |
| ------------------------ | ---------------------------- | -------------------- | ---------------------------- | ------------------------ |
| **MemoryHistoryStorage** | è¿›ç¨‹çº§éš”ç¦»ï¼Œchannel ç‹¬ç«‹å­˜å‚¨ | å•èŠ‚ç‚¹éƒ¨ç½²ã€æµ‹è¯•ç¯å¢ƒ | æå¿«çš„è¯»å†™é€Ÿåº¦               | é‡å¯ä¸¢å¤±ã€æ— æ³•åˆ†å¸ƒå¼å…±äº« |
| **RedisHistoryStorage**  | åˆ†å¸ƒå¼éš”ç¦»ï¼Œchannel ç‹¬ç«‹é”®   | åˆ†å¸ƒå¼ç”Ÿäº§ç¯å¢ƒ       | æŒä¹…åŒ–ã€åˆ†å¸ƒå¼å…±äº«ã€TTL æ”¯æŒ | ç½‘ç»œå»¶è¿Ÿã€å†…å­˜æˆæœ¬       |

### 6.3 Redis å­˜å‚¨çš„éš”ç¦»å®ç°

**æ ¸å¿ƒè®¾è®¡**ï¼šæ¯ä¸ª channel ç‹¬ç«‹çš„ Redis é”®ç©ºé—´ï¼Œå®ç°å­˜å‚¨çº§åˆ«çš„éš”ç¦»

```redis
# ä¸åŒ channel å®Œå…¨éš”ç¦»çš„å­˜å‚¨ç»“æ„

# Channel A çš„æ¶ˆæ¯å­˜å‚¨
XADD livechat:history:stream:channel-a * data <protobuf-data>
HSET livechat:history:meta:channel-a epoch "abc123-1609459200" updated_at 1609459200
EXPIRE livechat:history:stream:channel-a 3600

# Channel B çš„æ¶ˆæ¯å­˜å‚¨  
XADD livechat:history:stream:channel-b * data <protobuf-data>
HSET livechat:history:meta:channel-b epoch "def456-1609459300" updated_at 1609459300
EXPIRE livechat:history:stream:channel-b 3600
```

**æŸ¥è¯¢æ—¶çš„éš”ç¦»ä¿è¯**ï¼š
```go
func (r *RedisHistoryStorage) GetHistory(ctx context.Context, channel string, opts HistoryOptions) ([]*Publication, StreamPosition, error) {
    // æ¯ä¸ª channel ç‹¬ç«‹çš„é”®ç©ºé—´ï¼Œå¤©ç„¶éš”ç¦»
    streamKey := r.getStreamKey(channel)    // ä¾‹å¦‚ï¼šlivechat:history:stream:channel-a
    metaKey := r.getMetaKey(channel)        // ä¾‹å¦‚ï¼šlivechat:history:meta:channel-a
    
    // åªæŸ¥è¯¢æŒ‡å®š channel çš„æ•°æ®ï¼Œæ— äº¤å‰æ±¡æŸ“
    streamResults, err := r.client.XRangeN(ctx, streamKey, start, end, int64(count)).Result()
    // ...
}
```

## 7. è®¢é˜…ç®¡ç†æœºåˆ¶

### 7.1 è®¢é˜…éš”ç¦»æ¶æ„

**æ ¸å¿ƒç†å¿µ**ï¼šN ä¸ª channels = 1 ä¸ª Kafka consumer + 1 ä¸ªå†…å­˜è·¯ç”±è¡¨

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚è®¢é˜…ç®¡ç†"
        SM[subscriptions<br/>sync.Map]
        SC[subscribedChannels<br/>map[string]bool]
        
        SM --> |channel-a: true| A[Channel A å·²è®¢é˜…]
        SM --> |channel-b: true| B[Channel B å·²è®¢é˜…] 
        SM --> |channel-c: false| C[Channel C æœªè®¢é˜…]
    end
    
    subgraph "Kafka å±‚"
        GC[å…¨å±€æ¶ˆè´¹è€…<br/>å•ä¸€ Consumer]
        UT[ç»Ÿä¸€ Topic<br/>centrifuge.messages]
        
        GC --> UT
    end
    
    subgraph "æ¶ˆæ¯æµ"
        M1[Message for A] --> GC
        M2[Message for B] --> GC
        M3[Message for C] --> GC
    end
    
    GC --> SM
    A --> H1[å¤„ç† Channel A æ¶ˆæ¯]
    B --> H2[å¤„ç† Channel B æ¶ˆæ¯] 
    C --> IG[å¿½ç•¥ Channel C æ¶ˆæ¯]
    
    style C fill:#ffebee
    style IG fill:#ffebee
```

### 7.2 è®¢é˜…æ“ä½œçš„éš”ç¦»å®ç°

**Subscribe æ“ä½œ**ï¼š
```go
func (b *KafkaBroker) Subscribe(ch string) error {
    if b.node.logEnabled(LogLevelDebug) {
        b.node.logger.log(newLogEntry(LogLevelDebug, "kafka broker subscribe to channel", map[string]any{
            "broker_name": b.config.Name,
            "channel":     ch,
        }))
    }

    // å…³é”®ï¼šåªåœ¨å†…å­˜ä¸­æ ‡è®°è®¢é˜…çŠ¶æ€ï¼Œä¸åˆ›å»ºæ–°çš„ Kafka æ¶ˆè´¹è€…
    b.subscriptions.Store(ch, true)

    // åŒé‡è®°å½•ç¡®ä¿ä¸€è‡´æ€§
    b.subscriptionMu.Lock()
    b.subscribedChannels[ch] = true
    b.subscriptionMu.Unlock()

    return nil
}
```

**Unsubscribe æ“ä½œ**ï¼š
```go
func (b *KafkaBroker) Unsubscribe(ch string) error {
    if b.node.logEnabled(LogLevelDebug) {
        b.node.logger.log(newLogEntry(LogLevelDebug, "kafka broker unsubscribe from channel", map[string]any{
            "broker_name": b.config.Name,
            "channel":     ch,
        }))
    }

    // ä»è®¢é˜…è¡¨ä¸­ç§»é™¤ï¼Œå®ç°é€»è¾‘éš”ç¦»
    b.subscriptions.Delete(ch)

    b.subscriptionMu.Lock()
    delete(b.subscribedChannels, ch)
    b.subscriptionMu.Unlock()

    return nil
}
```

### 7.3 å…¨å±€æ¶ˆè´¹è€…çš„éš”ç¦»ç­–ç•¥

```go
func (b *KafkaBroker) startGlobalConsumer() error {
    b.subscriptionMu.Lock()
    defer b.subscriptionMu.Unlock()

    if b.isSubscribed {
        return nil // ç¡®ä¿åªæœ‰ä¸€ä¸ªå…¨å±€æ¶ˆè´¹è€…
    }

    go func() {
        for {
            select {
            case <-b.stopCh:
                return
            default:
                // å¯åŠ¨å•ä¸€æ¶ˆè´¹è€…ï¼Œå¤„ç†æ‰€æœ‰æ¶ˆæ¯
                err := b.kafkaBroker.Subscribe(
                    context.Background(),
                    b.messagesTopic,                    // ç»Ÿä¸€ topic
                    b.config.ConsumerGroupID,
                    b.handleMessage,                    // ç»Ÿä¸€å¤„ç†å™¨ï¼ˆå†…å«éš”ç¦»é€»è¾‘ï¼‰
                    commonBroker.WithSubPullGoroutines(2),
                    commonBroker.WithEnableSubUseMsgBuffer(),
                    commonBroker.WithSubMsgBufferSize(1024),
                    commonBroker.WithSubMsgBufferGoroutines(4),
                )
                
                if err != nil {
                    b.node.logger.log(newErrorLogEntry(err, "kafka broker global consumer failed", map[string]any{
                        "topic":       b.messagesTopic,
                        "broker_name": b.config.Name,
                    }))
                    // è‡ªåŠ¨é‡è¯•
                    select {
                    case <-b.stopCh:
                        return
                    case <-time.After(5 * time.Second):
                        continue
                    }
                }
            }
        }
    }()

    b.isSubscribed = true
    return nil
}
```

## 8. é”™è¯¯å¤„ç†å’Œé‡è¯•

### 8.1 éš”ç¦»å¼é”™è¯¯å¤„ç†

**è®¾è®¡åŸåˆ™**ï¼šå•ä¸ª channel çš„é”™è¯¯ä¸åº”è¯¥å½±å“å…¶ä»– channel çš„æ¶ˆæ¯å¤„ç†

```go
// 1. æ¶ˆæ¯çº§é”™è¯¯éš”ç¦»
func (b *KafkaBroker) handleMessage(ctx context.Context, data []byte) error {
    var msgWrapper KafkaMessage
    if err := json.Unmarshal(data, &msgWrapper); err != nil {
        // è§£æé”™è¯¯ï¼šè®°å½•ä½†ä¸ä¸­æ–­æ•´ä½“æ¶ˆè´¹
        b.node.logger.log(newErrorLogEntry(err, "failed to unmarshal kafka message", nil))
        return nil // è¿”å› nil ç»§ç»­å¤„ç†ä¸‹ä¸€æ¡æ¶ˆæ¯
    }
    
    // è®¢é˜…æ£€æŸ¥é”™è¯¯ä¸ä¼šå½±å“å…¶ä»–æ¶ˆæ¯
    if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
        return nil // éš”ç¦»ï¼šæœªè®¢é˜…æ¶ˆæ¯ç›´æ¥å¿½ç•¥
    }
    
    // æ¶ˆæ¯å¤„ç†é”™è¯¯è¿›è¡Œéš”ç¦»å¤„ç†
    switch msgWrapper.Type {
    case MessageTypePublication:
        if err := b.handlePublication(msgWrapper); err != nil {
            b.node.logger.log(newErrorLogEntry(err, "failed to handle publication", map[string]any{
                "channel": msgWrapper.Channel,
            }))
            // ä¸è¿”å›é”™è¯¯ï¼Œé¿å…å½±å“å…¶ä»– channel
        }
        return nil
    }
}

// 2. Channel çº§é”™è¯¯éš”ç¦»
func (b *KafkaBroker) handlePublication(msgWrapper KafkaMessage) error {
    var pub protocol.Publication
    if err := pub.UnmarshalVT(msgWrapper.Data); err != nil {
        // ç‰¹å®š channel çš„æ¶ˆæ¯è§£æé”™è¯¯ï¼Œåªå½±å“è¯¥ channel
        b.node.logger.log(newErrorLogEntry(err, "failed to unmarshal publication", map[string]any{
            "channel": msgWrapper.Channel,
        }))
        return err // è¿”å›é”™è¯¯ï¼Œä½†å·²è¢«ä¸Šå±‚æ•è·å¤„ç†
    }

    pub.Offset = msgWrapper.StreamPosition.Offset

    // EventHandler é”™è¯¯ä¹Ÿè¢«éš”ç¦»å¤„ç†
    return b.eventHandler.HandlePublication(
        msgWrapper.Channel,
        pubFromProto(&pub),
        msgWrapper.StreamPosition,
        false,
        nil,
    )
}
```

### 8.2 å†å²å­˜å‚¨é”™è¯¯çš„éš”ç¦»å¤„ç†

```go
func (b *KafkaBroker) Publish(ch string, data []byte, opts PublishOptions) (StreamPosition, bool, error) {
    var sp StreamPosition
    if opts.HistorySize > 0 && opts.HistoryTTL > 0 {
        publication := pubFromProto(protoPub)
        sp, err = b.historyStorage.AddToHistory(context.Background(), ch, publication, opts)
        if err != nil {
            // å†å²å­˜å‚¨å¤±è´¥çš„éš”ç¦»å¤„ç†ç­–ç•¥
            b.node.logger.log(newErrorLogEntry(err, "failed to add to history", map[string]any{
                "channel": ch,
            }))
            
            // ä¼˜é›…é™çº§ï¼šå†å²å­˜å‚¨å¤±è´¥ä¸å½±å“å®æ—¶æ¶ˆæ¯å‘å¸ƒ
            // é€‰æ‹©ç»§ç»­å‘å¸ƒæ¶ˆæ¯ï¼Œä¿è¯æ¶ˆæ¯çš„å®æ—¶æ€§
            sp = StreamPosition{} // ä½¿ç”¨ç©ºçš„æµä½ç½®
        }
    }
    
    // ç»§ç»­ Kafka å‘å¸ƒæµç¨‹ï¼Œä¿è¯å®æ—¶æ¶ˆæ¯ä¸å—å†å²å­˜å‚¨å½±å“
    // ...
}
```

## 9. æ€§èƒ½ä¼˜åŒ–è®¾è®¡

### 9.1 éš”ç¦»æœºåˆ¶çš„æ€§èƒ½ä¼˜åŒ–

**1. é«˜æ•ˆçš„è®¢é˜…çŠ¶æ€æ£€æŸ¥**ï¼š
```go
// ä½¿ç”¨ sync.Map å®ç°æ— é”é«˜å¹¶å‘è¯»å†™
type KafkaBroker struct {
    subscriptions sync.Map // map[string]bool - æ”¯æŒé«˜å¹¶å‘è®¢é˜…æ£€æŸ¥
}

// O(1) æ—¶é—´å¤æ‚åº¦çš„è®¢é˜…æ£€æŸ¥
if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
    return nil // æä½å»¶è¿Ÿçš„éš”ç¦»åˆ¤æ–­
}
```

**2. æ¶ˆæ¯æ‰¹å¤„ç†ä¼˜åŒ–**ï¼š
```go
// ä¼˜åŒ–æ¶ˆè´¹è€…é…ç½®ï¼Œæé«˜æ‰¹å¤„ç†æ•ˆç‡
err := b.kafkaBroker.Subscribe(
    context.Background(),
    b.messagesTopic,
    b.config.ConsumerGroupID,
    b.handleMessage,
    commonBroker.WithSubPullGoroutines(2),        // 2 ä¸ªæ‹‰å–åç¨‹
    commonBroker.WithEnableSubUseMsgBuffer(),     // å¯ç”¨æ¶ˆæ¯ç¼“å†²
    commonBroker.WithSubMsgBufferSize(1024),      // ç¼“å†²åŒºå¤§å° 1024
    commonBroker.WithSubMsgBufferGoroutines(4),   // 4 ä¸ªå¤„ç†åç¨‹
)
```

**3. æ™ºèƒ½åˆ†åŒºç­–ç•¥**ï¼š
```go
// ä½¿ç”¨ channel åç§°ä½œä¸ºåˆ†åŒºé”®ï¼Œä¼˜åŒ–è´Ÿè½½åˆ†å¸ƒå’Œæ¶ˆæ¯æœ‰åºæ€§
err = b.kafkaBroker.Publish(
    context.Background(),
    b.messagesTopic,
    msgData,
    commonBroker.WithPublishName(ch), // channel ä½œä¸ºåˆ†åŒºé”®
)
```

### 9.2 å†…å­˜ä½¿ç”¨ä¼˜åŒ–

```go
// 1. è®¢é˜…çŠ¶æ€ä½¿ç”¨è½»é‡çº§å­˜å‚¨
type KafkaBroker struct {
    subscriptions sync.Map // æ— é”è¯»å†™ï¼Œå†…å­˜æ•ˆç‡é«˜
    
    // 2. é¿å…é¢‘ç¹çš„ map æ“ä½œï¼Œæ‰¹é‡æ“ä½œæ—¶ä½¿ç”¨ç‹¬ç«‹ç»“æ„
    subscriptionMu     sync.RWMutex
    subscribedChannels map[string]bool // ä»…åœ¨æ‰¹é‡æ“ä½œæ—¶ä½¿ç”¨
}

// 3. æ¶ˆæ¯åŒ…è£…å™¨ä½¿ç”¨ç´§å‡‘è®¾è®¡
type KafkaMessage struct {
    Type           MessageType    `json:"type"`            // 1 byte
    Channel        string         `json:"channel"`         // å˜é•¿ï¼ŒæŒ‰éœ€åˆ†é…  
    Data           []byte         `json:"data"`            // å¼•ç”¨ï¼Œæ— é¢å¤–æ‹·è´
    StreamPosition StreamPosition `json:"stream_position,omitempty"` // æŒ‰éœ€åºåˆ—åŒ–
}
```

### 9.3 æ€§èƒ½ç›‘æ§æŒ‡æ ‡

| ç›‘æ§æŒ‡æ ‡           | å«ä¹‰                        | ä¼˜åŒ–ç›®æ ‡             |
| ------------------ | --------------------------- | -------------------- |
| **è®¢é˜…æ£€æŸ¥å»¶è¿Ÿ**   | `subscriptions.Load()` è€—æ—¶ | < 1Î¼s                |
| **æ¶ˆæ¯è·¯ç”±å»¶è¿Ÿ**   | ä»æ¥æ”¶åˆ°å¤„ç†å™¨çš„è€—æ—¶        | < 100Î¼s              |
| **éš”ç¦»è¿‡æ»¤ç‡**     | è¢«éš”ç¦»å¿½ç•¥çš„æ¶ˆæ¯æ¯”ä¾‹        | æ ¹æ®è®¢é˜…æƒ…å†µè€Œå®š     |
| **åˆ†åŒºåˆ†å¸ƒå‡åŒ€åº¦** | å„åˆ†åŒºæ¶ˆæ¯é‡çš„æ ‡å‡†å·®        | è¶Šå°è¶Šå¥½             |
| **ç¼“å†²åŒºä½¿ç”¨ç‡**   | æ¶ˆæ¯ç¼“å†²åŒºçš„å¹³å‡ä½¿ç”¨ç‡      | 60-80%ï¼ˆé¿å…ç§¯å‹ï¼‰   |
| **å†…å­˜ä½¿ç”¨é‡**     | è®¢é˜…è¡¨å’Œç¼“å†²åŒºçš„å†…å­˜å ç”¨    | çº¿æ€§å¢é•¿ï¼Œå¯æ§èŒƒå›´å†… |

## 10. ä¸ Redis Broker å¯¹æ¯”

### 10.1 éš”ç¦»æœºåˆ¶å¯¹æ¯”

| éš”ç¦»ç‰¹æ€§         | Kafka Broker                      | Redis Broker                    |
| ---------------- | --------------------------------- | ------------------------------- |
| **éš”ç¦»çº§åˆ«**     | é€»è¾‘éš”ç¦»ï¼ˆåº”ç”¨å±‚ï¼‰                | ç‰©ç†éš”ç¦»ï¼ˆæ¯ channel ç‹¬ç«‹è®¢é˜…ï¼‰ |
| **è¿æ¥æ•°**       | 1 ä¸ªè¿æ¥å¤„ç†æ‰€æœ‰ channel          | N ä¸ª channel = N ä¸ªè¿æ¥         |
| **éš”ç¦»æ£€æŸ¥**     | O(1) å†…å­˜æŸ¥è¡¨                     | ç”± Redis æœåŠ¡ç«¯å¤„ç†             |
| **æ¶ˆæ¯æœ‰åºæ€§**   | åˆ†åŒºå†…æœ‰åº                        | å‘å¸ƒé¡ºåºæœ‰åº                    |
| **éš”ç¦»æ•…éšœå½±å“** | å• channel é”™è¯¯ä¸å½±å“å…¶ä»– channel | è¿æ¥çº§æ•…éšœå¯èƒ½å½±å“å¤šä¸ª channel  |
| **æ‰©å±•æ€§**       | å‡ ä¹æ— é™ channel                  | å— Redis è¿æ¥æ•°é™åˆ¶             |

### 10.2 æ€§èƒ½æ•°æ®å¯¹æ¯”

| æŒ‡æ ‡                         | Kafka Broker (é€»è¾‘éš”ç¦») | Redis Broker (ç‰©ç†éš”ç¦») |
| ---------------------------- | ----------------------- | ----------------------- |
| **å‘å¸ƒå»¶è¿Ÿ**                 | 2-8ms                   | 0.5-2ms                 |
| **æ¶ˆè´¹å»¶è¿Ÿ**                 | 3-12ms                  | 0.2-1ms                 |
| **éš”ç¦»æ£€æŸ¥å»¶è¿Ÿ**             | ~1Î¼s (å†…å­˜æŸ¥è¡¨)         | 0 (æœåŠ¡ç«¯å¤„ç†)          |
| **ååé‡ (é«˜è®¢é˜…æ•°)**        | 120K+ msg/s             | 60K+ msg/s              |
| **å†…å­˜ä½¿ç”¨ (1000 channels)** | ~50MB (è®¢é˜…è¡¨)          | ~200MB (è¿æ¥æ± )         |
| **CPU ä½¿ç”¨**                 | ä¸­ç­‰ (æ¶ˆæ¯è§£æå¼€é”€)     | è¾ƒä½ (åè®®ç®€å•)         |
| **è¿æ¥æ•° (1000 channels)**   | 1                       | 1000                    |

### 10.3 ä½¿ç”¨åœºæ™¯å»ºè®®

**é€‰æ‹© Kafka Broker çš„åœºæ™¯**ï¼š
- âœ… **å¤§è§„æ¨¡ channel æ•°é‡** (>1000 channels)
- âœ… **éœ€è¦æ¶ˆæ¯æŒä¹…åŒ–**å’Œé«˜å¯é æ€§
- âœ… **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼Œå¤šèŠ‚ç‚¹å…±äº«æ¶ˆæ¯
- âœ… **æ¶ˆæ¯å®¡è®¡**å’Œå†å²å›æº¯éœ€æ±‚
- âœ… **èµ„æºä½¿ç”¨ä¼˜åŒ–** (å‡å°‘è¿æ¥æ•°)
- âœ… **å·²æœ‰ Kafka åŸºç¡€è®¾æ–½**

**é€‰æ‹© Redis Broker çš„åœºæ™¯**ï¼š
- âœ… **æä½å»¶è¿Ÿè¦æ±‚** (<1ms)
- âœ… **ä¸­å°è§„æ¨¡ channel æ•°é‡** (<500 channels)  
- âœ… **ç®€å•éƒ¨ç½²**ï¼Œè¿ç»´èµ„æºæœ‰é™
- âœ… **å·²æœ‰ Redis åŸºç¡€è®¾æ–½**
- âœ… **æ¶ˆæ¯ä¸´æ—¶æ€§**ï¼Œæ— æŒä¹…åŒ–éœ€æ±‚

### 10.4 æ··åˆéƒ¨ç½²å»ºè®®

å¯¹äºå¤æ‚çš„åº”ç”¨åœºæ™¯ï¼Œå¯ä»¥è€ƒè™‘æ··åˆä½¿ç”¨ï¼š

```yaml
# é…ç½®ç¤ºä¾‹ï¼šæ ¹æ® channel ç‰¹æ€§é€‰æ‹© broker
channel_routing:
  # é«˜é¢‘ã€ä¸´æ—¶æ¶ˆæ¯ä½¿ç”¨ Redis Broker
  "chat:*": redis_broker
  "notification:*": redis_broker
  
  # éœ€è¦æŒä¹…åŒ–çš„æ¶ˆæ¯ä½¿ç”¨ Kafka Broker  
  "order:*": kafka_broker
  "audit:*": kafka_broker
  
  # å¤§è§„æ¨¡è®¢é˜…ä½¿ç”¨ Kafka Broker
  "broadcast:*": kafka_broker
```

## æ€»ç»“

Kafka Broker é‡‡ç”¨**é€»è¾‘éš”ç¦»**è®¾è®¡ï¼Œåœ¨ä¿è¯ channel é—´å®Œå…¨éš”ç¦»çš„åŒæ—¶ï¼Œå®ç°äº†èµ„æºä½¿ç”¨çš„æœ€ä¼˜åŒ–ã€‚

### ğŸ—ï¸ **éš”ç¦»æœºåˆ¶ä¼˜åŠ¿**
- **é€»è¾‘éš”ç¦»**ï¼šé€šè¿‡åº”ç”¨å±‚è®¢é˜…æ£€æŸ¥å®ç°å®Œå…¨çš„ channel éš”ç¦»
- **èµ„æºé›†çº¦**ï¼šN ä¸ª channel åªéœ€ 1 ä¸ª Kafka è¿æ¥å’Œ topic
- **æ€§èƒ½ä¼˜åŒ–**ï¼šO(1) æ—¶é—´å¤æ‚åº¦çš„éš”ç¦»æ£€æŸ¥ï¼Œå¾®ç§’çº§å»¶è¿Ÿ

### ğŸš€ **æ¶æ„ä¼˜åŠ¿**  
- **ç»Ÿä¸€æ¶ˆæ¯æµ**ï¼šå•ä¸€ topic å¤„ç†æ‰€æœ‰æ¶ˆæ¯ç±»å‹ï¼Œé™ä½è¿ç»´å¤æ‚åº¦
- **æ™ºèƒ½åˆ†åŒº**ï¼šåŸºäº channel çš„åˆ†åŒºç­–ç•¥ï¼Œä¿è¯æ¶ˆæ¯æœ‰åºæ€§
- **ä¼˜é›…é™çº§**ï¼šå• channel é”™è¯¯ä¸å½±å“æ•´ä½“ç³»ç»Ÿç¨³å®šæ€§

### ğŸ›¡ï¸ **å¯é æ€§ä¼˜åŠ¿**
- **æ•…éšœéš”ç¦»**ï¼šæ¶ˆæ¯çº§ã€channel çº§çš„å¤šå±‚é”™è¯¯éš”ç¦»
- **è‡ªåŠ¨é‡è¯•**ï¼šè¿æ¥çº§å’Œæ¶ˆæ¯çº§çš„æ™ºèƒ½é‡è¯•æœºåˆ¶
- **ç›‘æ§å®Œå¤‡**ï¼šè¯¦ç»†çš„éš”ç¦»æŒ‡æ ‡å’Œæ€§èƒ½æ•°æ®

### ğŸ“Š **é€‚ç”¨åœºæ™¯**
- **å¤§è§„æ¨¡**ï¼šæ”¯æŒæ•°åƒä¸ª channel çš„é«˜å¹¶å‘åœºæ™¯
- **ä¼ä¸šçº§**ï¼šéœ€è¦æ¶ˆæ¯æŒä¹…åŒ–ã€å®¡è®¡ã€åˆ†å¸ƒå¼éƒ¨ç½²
- **é«˜å¯é **ï¼šå¯¹æ¶ˆæ¯ä¸ä¸¢å¤±ã€ç³»ç»Ÿé«˜å¯ç”¨æœ‰è¦æ±‚çš„åœºæ™¯

Kafka Broker çš„é€»è¾‘éš”ç¦»æœºåˆ¶åœ¨ä¿è¯å®Œå…¨éš”ç¦»çš„å‰æä¸‹ï¼Œå®ç°äº†æ€§èƒ½å’Œèµ„æºä½¿ç”¨çš„æœ€ä½³å¹³è¡¡ï¼Œæ˜¯å¤§è§„æ¨¡åˆ†å¸ƒå¼å®æ—¶é€šè®¯ç³»ç»Ÿçš„ç†æƒ³é€‰æ‹©ã€‚

