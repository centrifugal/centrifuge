# Kafka Broker å®ç°åŸç†æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸºäº Kafka çš„ Centrifuge Broker å®ç°åŸç†ã€æ¶æ„è®¾è®¡å’Œæ ¸å¿ƒæœºåˆ¶ã€‚

## ğŸ“‹ ç›®å½•

- [1. æ€»ä½“æ¶æ„](#1-æ€»ä½“æ¶æ„)
- [2. æ ¸å¿ƒç»„ä»¶](#2-æ ¸å¿ƒç»„ä»¶)
- [3. æ¶ˆæ¯æµè½¬æœºåˆ¶](#3-æ¶ˆæ¯æµè½¬æœºåˆ¶)
- [4. å†å²å­˜å‚¨è®¾è®¡](#4-å†å²å­˜å‚¨è®¾è®¡)
- [5. è®¢é˜…ç®¡ç†æœºåˆ¶](#5-è®¢é˜…ç®¡ç†æœºåˆ¶)
- [6. é”™è¯¯å¤„ç†å’Œé‡è¯•](#6-é”™è¯¯å¤„ç†å’Œé‡è¯•)
- [7. æ€§èƒ½ä¼˜åŒ–è®¾è®¡](#7-æ€§èƒ½ä¼˜åŒ–è®¾è®¡)
- [8. ä¸ Redis Broker å¯¹æ¯”](#8-ä¸-redis-broker-å¯¹æ¯”)

## 1. æ€»ä½“æ¶æ„

### 1.1 æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "Centrifuge Nodes"
        N1[Node 1]
        N2[Node 2] 
        N3[Node 3]
    end
    
    subgraph "Kafka Cluster"
        K1[Kafka Broker 1]
        K2[Kafka Broker 2]
        K3[Kafka Broker 3]
    end
    
    subgraph "History Storage"
        RS[Redis Streams]
        MS[Memory Storage]
    end
    
    N1 --> K1
    N2 --> K2
    N3 --> K3
    
    N1 -.-> RS
    N2 -.-> RS
    N3 -.-> RS
    
    N1 -.-> MS
    N2 -.-> MS
    N3 -.-> MS
```

### 1.2 è®¾è®¡åŸåˆ™

| åŸåˆ™             | å®ç°æ–¹å¼                      | ä¼˜åŠ¿                         |
| ---------------- | ----------------------------- | ---------------------------- |
| **æ¶ˆæ¯éš”ç¦»**     | ç»Ÿä¸€ topic + æ¶ˆæ¯ç±»å‹è·¯ç”±     | å‡å°‘ Kafka è¿æ¥æ•°ï¼Œæé«˜æ€§èƒ½  |
| **åˆ†å¸ƒå¼ä¸€è‡´æ€§** | å¯æ’æ‹”å†å²å­˜å‚¨æ¥å£            | æ”¯æŒ Redis/Memory ç­‰å¤šç§å­˜å‚¨ |
| **é«˜å¯ç”¨æ€§**     | åŸºäº Common åŒ…çš„ Kafka å®¢æˆ·ç«¯ | è‡ªåŠ¨é‡è¿ã€é”™è¯¯é‡è¯•           |
| **å¯è§‚æµ‹æ€§**     | å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§æ¥å£          | ä¾¿äºè¿ç»´å’Œé—®é¢˜æ’æŸ¥           |

## 2. æ ¸å¿ƒç»„ä»¶

### 2.1 ç»„ä»¶å…³ç³»å›¾

```go
// æ ¸å¿ƒç»„ä»¶ç»“æ„
type KafkaBroker struct {
    node           *Node                    // Centrifuge èŠ‚ç‚¹å¼•ç”¨
    config         KafkaBrokerConfig        // é…ç½®ä¿¡æ¯
    kafkaBroker    commonBroker.Broker      // Common åŒ… Kafka å®¢æˆ·ç«¯
    eventHandler   BrokerEventHandler       // äº‹ä»¶å¤„ç†å™¨
    subscriptions  sync.Map                 // è®¢é˜…ç®¡ç†ï¼šmap[string]bool
    historyStorage HistoryStorage           // å†å²å­˜å‚¨æ¥å£
    
    // Topic ç®¡ç†
    messagesTopic  string                   // ç»Ÿä¸€æ¶ˆæ¯ topic
    
    // è®¢é˜…çŠ¶æ€ç®¡ç†
    subscriptionMu     sync.RWMutex         // è®¢é˜…é”
    isSubscribed       bool                 // å…¨å±€è®¢é˜…çŠ¶æ€
    subscribedChannels map[string]bool      // å·²è®¢é˜… channel åˆ—è¡¨
    
    // ç”Ÿå‘½å‘¨æœŸç®¡ç†
    closeOnce      sync.Once               // ç¡®ä¿åªå…³é—­ä¸€æ¬¡
    stopCh         chan struct{}           // åœæ­¢ä¿¡å·
}
```

### 2.2 é…ç½®ç»„ä»¶

```go
type KafkaBrokerConfig struct {
    // Kafka é…ç½® - ç›´æ¥ä½¿ç”¨ Common åŒ…
    KafkaConfig gkafka.KafkaConfig
    
    // Centrifuge ç‰¹æœ‰é…ç½®
    TopicPrefix     string           // Topic å‰ç¼€ï¼Œé»˜è®¤ "centrifuge"
    ConsumerGroupID string           // æ¶ˆè´¹è€…ç»„ ID
    Name           string           // Broker åç§°ï¼Œç”¨äºæ—¥å¿—å’Œç›‘æ§
    
    // å†å²å­˜å‚¨é…ç½®
    HistoryStorage HistoryStorage   // å¯æ’æ‹”çš„å†å²å­˜å‚¨
    
    // æ€§èƒ½é…ç½®
    NumPartitions  int              // Topic åˆ†åŒºæ•°ï¼Œé»˜è®¤ 1
}
```

## 3. æ¶ˆæ¯æµè½¬æœºåˆ¶

### 3.1 æ¶ˆæ¯ç»Ÿä¸€åŒ–è®¾è®¡

**å…³é”®åˆ›æ–°**ï¼šæ‰€æœ‰æ¶ˆæ¯ç±»å‹éƒ½é€šè¿‡å•ä¸€ Kafka Topic ä¼ è¾“ï¼Œä½¿ç”¨æ¶ˆæ¯åŒ…è£…å™¨è¿›è¡Œç±»å‹åŒºåˆ†ã€‚

```go
// æ¶ˆæ¯åŒ…è£…å™¨
type KafkaMessage struct {
    Type           MessageType    `json:"type"`            // æ¶ˆæ¯ç±»å‹
    Channel        string         `json:"channel"`         // ç›®æ ‡ channel
    Data           []byte         `json:"data"`            // æ¶ˆæ¯æ•°æ® (protobuf)
    StreamPosition StreamPosition `json:"stream_position,omitempty"` // æµä½ç½®ä¿¡æ¯
}

// æ¶ˆæ¯ç±»å‹å®šä¹‰
const (
    MessageTypePublication MessageType = iota  // æ™®é€šæ¶ˆæ¯
    MessageTypeJoin                           // ç”¨æˆ·åŠ å…¥
    MessageTypeLeave                          // ç”¨æˆ·ç¦»å¼€
)
```

### 3.2 å‘å¸ƒæµç¨‹

```mermaid
sequenceDiagram
    participant C as Client
    participant N as Node
    participant KB as KafkaBroker
    participant HS as HistoryStorage
    participant K as Kafka

    C->>N: Publish Message
    N->>KB: Publish(channel, data, opts)
    
    alt History Enabled
        KB->>HS: AddToHistory(channel, pub, opts)
        HS-->>KB: StreamPosition
    end
    
    KB->>KB: Wrap Message (KafkaMessage)
    KB->>K: Publish to messagesTopic
    K-->>KB: Success
    KB-->>N: StreamPosition
    N-->>C: Publish Result
```

**å…³é”®ä»£ç **ï¼š
```go
func (b *KafkaBroker) Publish(ch string, data []byte, opts PublishOptions) (StreamPosition, bool, error) {
    // 1. åˆ›å»º protobuf æ¶ˆæ¯
    protoPub := &protocol.Publication{
        Data: data,
        Info: infoToProto(opts.ClientInfo),
        Tags: opts.Tags,
        Time: time.Now().UnixMilli(),
    }

    // 2. å¤„ç†å†å²å­˜å‚¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    var sp StreamPosition
    if opts.HistorySize > 0 && opts.HistoryTTL > 0 {
        publication := pubFromProto(protoPub)
        sp, err = b.historyStorage.AddToHistory(context.Background(), ch, publication, opts)
        if err != nil {
            return StreamPosition{}, false, fmt.Errorf("failed to add to history: %w", err)
        }
    }

    // 3. åŒ…è£…æ¶ˆæ¯
    msgWrapper := KafkaMessage{
        Type:           MessageTypePublication,
        Channel:        ch,
        Data:           byteMessage,
        StreamPosition: sp,
    }

    // 4. å‘å¸ƒåˆ° Kafka (ä½¿ç”¨ channel ä½œä¸ºåˆ†åŒºé”®)
    err = b.kafkaBroker.Publish(
        context.Background(),
        b.messagesTopic,
        msgData,
        commonBroker.WithPublishName(ch), // åˆ†åŒºé”®
    )

    return sp, false, err
}
```

### 3.3 æ¶ˆè´¹å¤„ç†æµç¨‹

```mermaid
flowchart TD
    A[Kafka Message] --> B{JSON Unmarshal}
    B -->|Success| C{Check Subscription}
    B -->|Error| D[Log Error & Skip]
    
    C -->|Subscribed| E{Message Type}
    C -->|Not Subscribed| F[Ignore Message]
    
    E -->|Publication| G[Handle Publication]
    E -->|Join| H[Handle Join]
    E -->|Leave| I[Handle Leave]
    
    G --> J[Call EventHandler]
    H --> J
    I --> J
    
    J --> K[Complete]
    D --> K
    F --> K
```

**ç»Ÿä¸€æ¶ˆæ¯å¤„ç†å™¨**ï¼š
```go
func (b *KafkaBroker) handleMessage(ctx context.Context, data []byte) error {
    // 1. è§£ææ¶ˆæ¯åŒ…è£…å™¨
    var msgWrapper KafkaMessage
    if err := json.Unmarshal(data, &msgWrapper); err != nil {
        return err
    }

    // 2. æ£€æŸ¥è®¢é˜…çŠ¶æ€
    if _, subscribed := b.subscriptions.Load(msgWrapper.Channel); !subscribed {
        return nil // å¿½ç•¥æœªè®¢é˜…çš„ channel
    }

    // 3. æ ¹æ®æ¶ˆæ¯ç±»å‹è·¯ç”±
    switch msgWrapper.Type {
    case MessageTypePublication:
        return b.handlePublication(msgWrapper)
    case MessageTypeJoin:
        return b.handleJoin(msgWrapper)
    case MessageTypeLeave:
        return b.handleLeave(msgWrapper)
    default:
        return fmt.Errorf("unknown message type: %d", msgWrapper.Type)
    }
}
```

## 4. å†å²å­˜å‚¨è®¾è®¡

### 4.1 å¯æ’æ‹”å­˜å‚¨æ¶æ„

```go
// å†å²å­˜å‚¨æ¥å£
type HistoryStorage interface {
    AddToHistory(ctx context.Context, channel string, pub *Publication, opts PublishOptions) (StreamPosition, error)
    GetHistory(ctx context.Context, channel string, opts HistoryOptions) ([]*Publication, StreamPosition, error)
    RemoveHistory(ctx context.Context, channel string) error
}
```

### 4.2 å­˜å‚¨å®ç°å¯¹æ¯”

| å­˜å‚¨ç±»å‹                 | é€‚ç”¨åœºæ™¯             | ä¼˜åŠ¿                         | åŠ£åŠ¿                     |
| ------------------------ | -------------------- | ---------------------------- | ------------------------ |
| **MemoryHistoryStorage** | å•èŠ‚ç‚¹éƒ¨ç½²ã€æµ‹è¯•ç¯å¢ƒ | æå¿«çš„è¯»å†™é€Ÿåº¦               | é‡å¯ä¸¢å¤±ã€æ— æ³•åˆ†å¸ƒå¼å…±äº« |
| **RedisHistoryStorage**  | åˆ†å¸ƒå¼ç”Ÿäº§ç¯å¢ƒ       | æŒä¹…åŒ–ã€åˆ†å¸ƒå¼å…±äº«ã€TTL æ”¯æŒ | ç½‘ç»œå»¶è¿Ÿã€å†…å­˜æˆæœ¬       |

### 4.3 Redis å­˜å‚¨åŸç†

**æ ¸å¿ƒè®¾è®¡**ï¼šä½¿ç”¨ Redis Streams + Hash çš„ç»„åˆå­˜å‚¨æ¨¡å¼

```redis
# æ¶ˆæ¯å­˜å‚¨ (Redis Stream)
XADD livechat:history:stream:chat:room:123 * data <protobuf-data>

# å…ƒæ•°æ®å­˜å‚¨ (Redis Hash)
HSET livechat:history:meta:chat:room:123 epoch "abc123-1609459200" updated_at 1609459200

# TTL ç®¡ç†
EXPIRE livechat:history:stream:chat:room:123 3600
EXPIRE livechat:history:meta:chat:room:123 3600
```

**æŸ¥è¯¢ä¼˜åŒ–**ï¼š
```go
// æ”¯æŒé«˜æ•ˆçš„èŒƒå›´æŸ¥è¯¢
func (r *RedisHistoryStorage) GetHistory(ctx context.Context, channel string, opts HistoryOptions) ([]*Publication, StreamPosition, error) {
    // æ„å»ºæŸ¥è¯¢å‚æ•°
    start, end, count := r.buildRangeArgs(opts.Filter, currentPos)
    
    // æ‰§è¡ŒèŒƒå›´æŸ¥è¯¢
    if opts.Filter.Reverse {
        streamResults, err = r.client.XRevRangeN(ctx, streamKey, end, start, int64(count)).Result()
    } else {
        streamResults, err = r.client.XRangeN(ctx, streamKey, start, end, int64(count)).Result()
    }
    
    // è½¬æ¢ä¸º Publication å¯¹è±¡
    return r.parseStreamMessages(streamResults), currentPos, nil
}
```

## 5. è®¢é˜…ç®¡ç†æœºåˆ¶

### 5.1 è®¢é˜…æ¶æ„
- å…¨å±€å•ä¸€æ¶ˆè´¹è€…ç›‘å¬ç»Ÿä¸€ topic
- åº”ç”¨å±‚è·¯ç”±åˆ°å…·ä½“ channel

```go
// è®¢é˜…æœºåˆ¶
// N ä¸ª channels = 1 ä¸ª Kafka consumer + å†…å­˜è·¯ç”±è¡¨

func (b *KafkaBroker) Subscribe(ch string) error {
    // åªéœ€è¦æ ‡è®°è®¢é˜…çŠ¶æ€ï¼Œä¸åˆ›å»ºæ–°çš„ Kafka æ¶ˆè´¹è€…
    b.subscriptions.Store(ch, true)
    
    b.subscriptionMu.Lock()
    b.subscribedChannels[ch] = true
    b.subscriptionMu.Unlock()
    
    return nil
}
```

### 5.2 å…¨å±€æ¶ˆè´¹è€…å¯åŠ¨

```go
func (b *KafkaBroker) startGlobalConsumer() error {
    go func() {
        for {
            select {
            case <-b.stopCh:
                return
            default:
                err := b.kafkaBroker.Subscribe(
                    context.Background(),
                    b.messagesTopic,
                    b.config.ConsumerGroupID,
                    b.handleMessage,               // ç»Ÿä¸€æ¶ˆæ¯å¤„ç†å™¨
                    commonBroker.WithSubPullGoroutines(2),
                    commonBroker.WithEnableSubUseMsgBuffer(),
                    commonBroker.WithSubMsgBufferSize(1024),
                    commonBroker.WithSubMsgBufferGoroutines(4),
                )
                
                if err != nil {
                    // è‡ªåŠ¨é‡è¯•é€»è¾‘
                    time.Sleep(5 * time.Second)
                    continue
                }
            }
        }
    }()
    
    return nil
}
```

## 6. é”™è¯¯å¤„ç†å’Œé‡è¯•

### 6.1 å¤šå±‚æ¬¡é”™è¯¯å¤„ç†

```go
// 1. Kafka è¿æ¥çº§é”™è¯¯å¤„ç†
func (b *KafkaBroker) startGlobalConsumer() error {
    go func() {
        for {
            select {
            case <-b.stopCh:
                return
            default:
                err := b.kafkaBroker.Subscribe(...)
                if err != nil {
                    b.node.logger.log(newErrorLogEntry(err, "kafka broker global consumer failed", map[string]any{
                        "topic":       b.messagesTopic,
                        "broker_name": b.config.Name,
                    }))
                    // æŒ‡æ•°é€€é¿é‡è¯•
                    select {
                    case <-b.stopCh:
                        return
                    case <-time.After(5 * time.Second):
                        continue
                    }
                }
            }
        }
    }()
}

// 2. æ¶ˆæ¯å¤„ç†çº§é”™è¯¯å¤„ç†
func (b *KafkaBroker) handleMessage(ctx context.Context, data []byte) error {
    var msgWrapper KafkaMessage
    if err := json.Unmarshal(data, &msgWrapper); err != nil {
        // è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æ¶ˆè´¹
        b.node.logger.log(newErrorLogEntry(err, "failed to unmarshal kafka message", nil))
        return nil // è¿”å› nil ç»§ç»­å¤„ç†ä¸‹ä¸€æ¡æ¶ˆæ¯
    }
    
    // æ¶ˆæ¯è·¯ç”±é”™è¯¯å¤„ç†
    switch msgWrapper.Type {
    case MessageTypePublication:
        if err := b.handlePublication(msgWrapper); err != nil {
            b.node.logger.log(newErrorLogEntry(err, "failed to handle publication", map[string]any{
                "channel": msgWrapper.Channel,
            }))
        }
    }
    return nil
}
```

### 6.2 å†å²å­˜å‚¨é”™è¯¯å¤„ç†

```go
func (b *KafkaBroker) Publish(ch string, data []byte, opts PublishOptions) (StreamPosition, bool, error) {
    var sp StreamPosition
    if opts.HistorySize > 0 && opts.HistoryTTL > 0 {
        publication := pubFromProto(protoPub)
        sp, err = b.historyStorage.AddToHistory(context.Background(), ch, publication, opts)
        if err != nil {
            // å†å²å­˜å‚¨å¤±è´¥æ—¶çš„å¤„ç†ç­–ç•¥
            b.node.logger.log(newErrorLogEntry(err, "failed to add to history", map[string]any{
                "channel": ch,
            }))
            
            // å¯ä»¥é€‰æ‹©ï¼š
            // 1. ç»§ç»­å‘å¸ƒæ¶ˆæ¯ï¼Œåªè®°å½•é”™è¯¯
            // 2. å¤±è´¥æ•´ä¸ªå‘å¸ƒæ“ä½œ
            // è¿™é‡Œé€‰æ‹©ç­–ç•¥ 1ï¼Œä¿è¯æ¶ˆæ¯çš„å®æ—¶æ€§
        }
    }
    
    // ç»§ç»­ Kafka å‘å¸ƒæµç¨‹...
}
```

## 7. æ€§èƒ½ä¼˜åŒ–è®¾è®¡

### 7.1 æ¶ˆæ¯æ‰¹å¤„ç†ä¼˜åŒ–

```go
// ä½¿ç”¨ Common åŒ…çš„æ‰¹å¤„ç†é…ç½®
err := b.kafkaBroker.Subscribe(
    context.Background(),
    b.messagesTopic,
    b.config.ConsumerGroupID,
    b.handleMessage,
    commonBroker.WithSubPullGoroutines(2),        // 2 ä¸ªæ‹‰å–åç¨‹
    commonBroker.WithEnableSubUseMsgBuffer(),     // å¯ç”¨æ¶ˆæ¯ç¼“å†²
    commonBroker.WithSubMsgBufferSize(1024),      // ç¼“å†²åŒºå¤§å° 1024
    commonBroker.WithSubMsgBufferGoroutines(4),   // 4 ä¸ªå¤„ç†åç¨‹
)
```

### 7.2 åˆ†åŒºç­–ç•¥ä¼˜åŒ–

```go
// ä½¿ç”¨ channel åç§°ä½œä¸ºåˆ†åŒºé”®ï¼Œç¡®ä¿åŒä¸€ channel çš„æ¶ˆæ¯æœ‰åº
err = b.kafkaBroker.Publish(
    context.Background(),
    b.messagesTopic,
    msgData,
    commonBroker.WithPublishName(ch), // channel ä½œä¸ºåˆ†åŒºé”®
)
```

### 7.3 å†…å­˜ä½¿ç”¨ä¼˜åŒ–

```go
// è®¢é˜…çŠ¶æ€ä½¿ç”¨ sync.Mapï¼Œæ”¯æŒé«˜å¹¶å‘è¯»å†™
type KafkaBroker struct {
    subscriptions sync.Map // map[string]bool - æ— é”è¯»å†™
    
    // é¿å…é¢‘ç¹çš„ map æ“ä½œ
    subscriptionMu     sync.RWMutex
    subscribedChannels map[string]bool // æ‰¹é‡æ“ä½œæ—¶ä½¿ç”¨
}
```

## 8. ä¸ Redis Broker å¯¹æ¯”

### 8.1 ç‰¹æ€§å¯¹æ¯”è¡¨

| ç‰¹æ€§           | Kafka Broker                | Redis Broker       |
| -------------- | --------------------------- | ------------------ |
| **æ¶ˆæ¯æŒä¹…åŒ–** | âœ… åŸç”Ÿæ”¯æŒï¼Œå¯é…ç½®ä¿ç•™ç­–ç•¥  | âŒ çº¯å†…å­˜ï¼Œé‡å¯ä¸¢å¤± |
| **åˆ†å¸ƒå¼æ‰©å±•** | âœ… åŸç”Ÿåˆ†åŒºå’Œå‰¯æœ¬æ”¯æŒ        | âœ… é€šè¿‡ Redis é›†ç¾¤  |
| **æ¶ˆæ¯é¡ºåº**   | âœ… åˆ†åŒºå†…ä¿è¯é¡ºåº            | âœ… å‘å¸ƒé¡ºåºä¿è¯     |
| **å†å²æ¶ˆæ¯**   | âœ… å¯æ’æ‹”å­˜å‚¨ (Redis/Memory) | âœ… å†…å­˜å­˜å‚¨         |
| **æ€§èƒ½**       | ğŸŸ¡ æ¯«ç§’çº§å»¶è¿Ÿ                | ğŸŸ¢ å¾®ç§’çº§å»¶è¿Ÿ       |
| **è¿ç»´å¤æ‚åº¦** | ğŸŸ¡ Kafka é›†ç¾¤ç®¡ç†            | ğŸŸ¢ Redis ç›¸å¯¹ç®€å•   |
| **æ¶ˆæ¯ç§¯å‹**   | âœ… å¯å¤„ç†å¤§é‡ç§¯å‹            | âŒ å—å†…å­˜é™åˆ¶       |
| **å¤šè¯­è¨€æ”¯æŒ** | âœ… ä¸°å¯Œçš„å®¢æˆ·ç«¯åº“            | âœ… ä¸°å¯Œçš„å®¢æˆ·ç«¯åº“   |

### 8.2 ä½¿ç”¨åœºæ™¯å»ºè®®

**é€‰æ‹© Kafka Broker çš„åœºæ™¯**ï¼š
- âœ… éœ€è¦æ¶ˆæ¯æŒä¹…åŒ–å’Œé«˜å¯é æ€§
- âœ… å¤§è§„æ¨¡åˆ†å¸ƒå¼éƒ¨ç½²
- âœ… æ¶ˆæ¯ååé‡è¦æ±‚é«˜
- âœ… éœ€è¦æ¶ˆæ¯å®¡è®¡å’Œå›æº¯
- âœ… å·²æœ‰ Kafka åŸºç¡€è®¾æ–½

**é€‰æ‹© Redis Broker çš„åœºæ™¯**ï¼š
- âœ… å¯¹å»¶è¿Ÿæå…¶æ•æ„Ÿ
- âœ… ä¸­å°è§„æ¨¡éƒ¨ç½²
- âœ… è¿ç»´èµ„æºæœ‰é™
- âœ… å·²æœ‰ Redis åŸºç¡€è®¾æ–½
- âœ… æ¶ˆæ¯ä¸´æ—¶æ€§ï¼Œæ— æŒä¹…åŒ–éœ€æ±‚

### 8.3 æ€§èƒ½æ•°æ®å¯¹æ¯”

| æŒ‡æ ‡         | Kafka Broker      | Redis Broker    |
| ------------ | ----------------- | --------------- |
| **å‘å¸ƒå»¶è¿Ÿ** | 1-5ms             | 0.1-1ms         |
| **æ¶ˆè´¹å»¶è¿Ÿ** | 1-10ms            | 0.1-1ms         |
| **ååé‡**   | 100K+ msg/s       | 50K+ msg/s      |
| **å†…å­˜ä½¿ç”¨** | è¾ƒä½ (ä¸»è¦åœ¨ç£ç›˜) | è¾ƒé«˜ (å…¨å†…å­˜)   |
| **CPU ä½¿ç”¨** | ä¸­ç­‰              | è¾ƒä½            |
| **ç½‘ç»œå¸¦å®½** | è¾ƒé«˜ (æ¶ˆæ¯è¾ƒå¤§)   | è¾ƒä½ (æ¶ˆæ¯è¾ƒå°) |

## æ€»ç»“

Kafka Broker æ˜¯ä¸ºåˆ†å¸ƒå¼ã€é«˜å¯é æ€§åœºæ™¯è®¾è®¡çš„ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

### ğŸ—ï¸ **æ¶æ„ä¼˜åŠ¿**
- **ç»Ÿä¸€æ¶ˆæ¯æµ**ï¼šå•ä¸€ topic å¤„ç†æ‰€æœ‰æ¶ˆæ¯ç±»å‹ï¼Œå¤§å¹…å‡å°‘èµ„æºæ¶ˆè€—
- **å¯æ’æ‹”å­˜å‚¨**ï¼šæ”¯æŒ Redis/Memory å¤šç§å†å²å­˜å‚¨æ–¹æ¡ˆ

### ğŸš€ **æ€§èƒ½ä¼˜åŠ¿**  
- **æ‰¹å¤„ç†**ï¼šæ¶ˆæ¯ç¼“å†²å’Œæ‰¹é‡å¤„ç†
- **åˆ†åŒºç­–ç•¥**ï¼šåŸºäº channel çš„æ™ºèƒ½åˆ†åŒº

### ğŸ›¡ï¸ **å¯é æ€§ä¼˜åŠ¿**
- **è‡ªåŠ¨é‡è¯•**ï¼šå¤šå±‚æ¬¡é”™è¯¯å¤„ç†å’Œæ¢å¤
- **ä¼˜é›…é™çº§**ï¼šå†å²å­˜å‚¨å¤±è´¥ä¸å½±å“å®æ—¶æ¶ˆæ¯
- **ç›‘æ§å®Œå¤‡**ï¼šè¯¦ç»†çš„æ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡

